---
layout: post
category: ml
comments: true
title: "Plotting with Seaborn - Part 1"
author: "Skander Kacem"
tags:
    - Visualization
    - Tutorial
    - Seaborn
    - Python
katex: true
---

# Plotting with Seaborn - Part 1

## The Matplotlib Problem

Picture this: You've just finished analyzing your data, discovered something interesting, and now you need to visualize it. You open up matplotlib and... three hours later, you're still tweaking axis labels, adjusting colors, and wrestling with legends that refuse to position themselves correctly. Sound familiar?

This is the matplotlib experience. Don't get me wrong—matplotlib is an incredible library. It gives you complete control over every pixel of your visualization. But that control comes at a cost: time. Lots of it.

What if there was a better way? What if you could create beautiful, publication-ready visualizations with just one or two lines of code? Enter Seaborn.

Seaborn sits on top of matplotlib and does all the tedious work for you. It automatically handles statistical aggregations, picks beautiful color schemes, creates informative legends, and makes your plots look professional by default. Think of it as matplotlib with a really good personal assistant—one that anticipates what you need before you ask.

In this tutorial, you'll discover how to create stunning visualizations efficiently. We'll start with the fundamentals, work through practical examples with real datasets, and by the end, you'll have a powerful toolkit for visual data exploration and communication.

## Navigating the Python Visualization Landscape

Before we dive into Seaborn, let's take a step back. The Python visualization ecosystem is... complex. There are dozens of libraries, each with their own philosophy and use cases. If you've felt overwhelmed trying to choose between them, you're not alone.

![The python Visualization Landscape](/assets/3/landscape.png)

The landscape looks chaotic because it evolved organically over years, with different libraries solving different problems. matplotlib provides low-level control, plotly creates interactive web visualizations, bokeh powers dashboards—the list goes on. For a fascinating deep dive into how we got here, check out [Jake Vanderplas' PyCon 2017 talk](https://www.youtube.com/watch?v=FytuB8nFHPQ).

Here's the good news: for data science and machine learning work, one library stands out above the rest. Seaborn has become the definitive choice for statistical data visualization, and once you understand why, you'll never want to go back.

### What Makes Seaborn Special

Imagine you're cooking dinner. matplotlib is like starting from individual ingredients—you have complete control, but you need to prep everything yourself. Seaborn is like having a meal kit delivered: the hard work is done, but you can still customize to taste.

When you give Seaborn a pandas DataFrame and tell it what kind of plot you want, magic happens under the hood. It automatically converts your data into visual attributes like colors and sizes. It computes statistical transformations like means and confidence intervals. It decorates your plot with clear labels and legends. And it does all of this while making aesthetic choices that would take you hours to configure in matplotlib.

But here's the beautiful part: Seaborn doesn't lock you out of matplotlib's power. When you need fine-grained control for that one tricky customization, matplotlib is right there, accessible and ready. You get the best of both worlds.

That said, understanding a bit about how matplotlib works will help you get the most out of Seaborn. We'll cover the essentials shortly, but first, let me show you why this matters with a simple comparison.

## Seeing is Believing: Matplotlib vs. Seaborn

Let's create a visualization using both libraries and see the difference for ourselves. We'll start by loading the tools we need:

```python
# imports
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Notebook settings
plt.rcParams['figure.figsize'] = 9, 4
```

Now we'll generate some random walk data—imagine tracking six different stocks over time:

```python
# Create random walk data
rng = np.random.RandomState(123)
x = np.linspace(0, 10, 500)
y = np.cumsum(rng.randn(500, 6), 0)

# Plot the data with matplotlib defaults
plt.style.use('classic')
plt.plot(x, y)
plt.legend('ABCDEF', ncol=2, loc='upper left');
```

![visualization of a simple random-walk with matplotlib pyplot](/assets/3/rndwlk_mpl.png)

There it is—a perfectly functional matplotlib plot. It shows all the information we need, and if you've used MATLAB before, you might even feel a bit nostalgic. This similarity to MATLAB wasn't accidental; it was a deliberate design choice that helped Python gain traction in scientific computing. The plot works, but aesthetically... well, it looks like something from the 1990s.

Now let's create the exact same plot, but this time we'll add just one line to enable Seaborn's styling:

```python
sns.set()
# Same plotting code as above
plt.plot(x, y)
plt.legend('ABCDEF', ncol=2, loc='upper left');
```

![visualization of a simple random-walk with seaborn classic settings](/assets/3/rndwlk_sns.png)

Look at that transformation. Better colors, cleaner grid lines, improved contrast—suddenly our plot looks like it belongs in a modern publication. And we achieved this by adding exactly one line of code.

This is Seaborn's philosophy in action: excellent defaults that require no effort. Before we go further, take a moment to browse the [Seaborn gallery](https://seaborn.pydata.org/examples/index.html). You'll see not just the range of visualizations possible, but the consistent professional quality they all share.

Here's something important to understand about data science: your work isn't done when you finish your analysis. You need to communicate your findings, often to people with very different backgrounds. Your engineering colleagues want technical details and precision. Your executives want clarity and big-picture insights. Creating separate visualizations for each audience wastes time.

With Seaborn, you don't have to choose. The plots you create during exploratory analysis are already polished enough to show stakeholders. This efficiency matters more than you might think—being able to effectively communicate your findings to diverse audiences often determines whether your work creates real impact.

## Understanding Matplotlib's Architecture

Now that you're motivated to learn Seaborn, let's briefly talk about matplotlib's structure. I promise this will be quick, and understanding these concepts will make you much more effective when you need to customize your plots.

Matplotlib has three layers: Backend (handles the rendering), Artist (manages visual elements), and Scripting (the interface you use). The Artist layer is where the magic happens—every single visual element in a plot, from lines to text to legends, is an Artist object that you can access and modify.

![Anatomy of a figure](/assets/3/anatomy.png)

Here's the thing though: Seaborn's defaults are so well-designed that you'll rarely need to dig into the Artist layer. The library's designers have already made thousands of aesthetic decisions for you, and they made them well. Your time is better spent understanding your data than tweaking plot aesthetics.

Still, when you do need customization, knowing these three concepts will save you hours of frustration: Figure, Axes, and Axis. People confuse these constantly, so let's clarify them once and for all.

### The Three Amigos: Figure, Axes, and Axis

Think of a Figure as the canvas—the entire window or page you're working with. It's the container for everything else. A Figure can hold multiple plots, just like a page in a magazine can have multiple images.

Let's create a Figure with four plots to see this in action:

```python
# create a figure with 4 axes
fig, ax = plt.subplots(nrows=2, ncols=2)

# Annotate the first subplot
ax[0, 0].annotate('This is an Axes',
                  (0.5, 0.5), color='r',
                  weight='bold', ha='center',
                  va='center', size=14)

# Set the axis limits of the second subplot
ax[0, 1].axis([0, 3, 0, 3])

# Title of the figure
plt.suptitle('One Figure with Four Axes', fontsize=18);
```

![figure object with four axes](/assets/3/1f4a.png)

Now, Axes (plural, with an 's') refers to an individual plot area—the region where your data lives. It's confusing because it sounds like "axis," but they're completely different things. Each Axes is like a picture frame containing one visualization. A Figure can have many Axes, but each Axes belongs to exactly one Figure.

```python
print(fig.axes)
# Output: [<AxesSubplot:>, <AxesSubplot:>, <AxesSubplot:>, <AxesSubplot:>]
```

Finally, Axis (singular) refers to the actual x-axis or y-axis—the number lines with tick marks. Each Axes contains two Axis objects (or three for 3D plots). When you set limits like "show x from 0 to 10," you're modifying an Axis object.

```python
# Print the axis limits of the second subplot
print(ax[0, 1].axis())
# Output: (0.0, 3.0, 0.0, 3.0)
```

Got it? Figure is the canvas, Axes are the individual plots, and Axis refers to the x and y number lines. Keep these straight, and you'll never be confused when reading documentation or Stack Overflow answers.

With that foundation in place, let's explore how Seaborn actually works.

## Two Flavors of Seaborn Functions

Here's something crucial that trips up many Seaborn beginners: not all Seaborn functions work the same way. They come in two distinct flavors, and understanding the difference will save you from frustration and confusion.

### Axes-Level Functions: The Team Players

The first type is called axes-level functions. These are the team players—they work with a single Axes object and play nicely with matplotlib. Think of them as well-behaved guests at a party who can mingle with anyone.

When you call an axes-level function, it creates a plot on a single Axes without affecting anything else in your Figure. This makes them perfect for building complex multi-plot layouts where you want precise control over what goes where.

Let me show you what I mean with a practical example. We'll load the famous penguins dataset—it contains measurements from three penguin species in Antarctica:

```python
# Load our dataset
penguins = sns.load_dataset('penguins')

# Create a figure with two subplots using matplotlib
fig, axs = plt.subplots(1, 2, figsize=(8, 4), 
                        gridspec_kw=dict(width_ratios=[4, 3]))

# Use Seaborn to generate a scatter plot on the first subplot
sns.scatterplot(data=penguins, x="flipper_length_mm", 
                y="bill_length_mm", hue="species", ax=axs[0])

# Use matplotlib to create a bar chart on the second subplot
species_counts = dict(penguins['species'].value_counts())
axs[1].bar(species_counts.keys(), species_counts.values(),
           color=['royalblue', 'darkseagreen', 'darkorange']);
```

![a matplotlib plot with a seaborn plot in the same figure](/assets/3/peng1.png)

See how seamlessly they work together? The `ax=axs[0]` parameter tells Seaborn exactly where to draw the plot. This is the power of axes-level functions—they integrate perfectly into any matplotlib workflow.

### Figure-Level Functions: The Showrunners

The second type is figure-level functions. These are the showrunners—they take charge of the entire Figure. When you call a figure-level function, it creates a complete figure from scratch and returns a special object called a FacetGrid.

Figure-level functions sacrifice some flexibility for convenience and power. You can't easily combine them with matplotlib plots, but they excel at creating consistent, multi-panel visualizations with minimal code.

Here's the relationship between the two types:

![Figure-level functions versus axes-level functions in seaborn](/assets/3/function_overview2.png)

Each figure-level function acts as a coordinator for several related axes-level functions. For example, `displot()` is the figure-level function that can create histograms, kernel density plots, and other distribution visualizations.

Let's see it in action:

```python
# Create a kernel density estimate plot
sns.displot(data=penguins, x="flipper_length_mm", hue="species",
            multiple="stack", kind="kde")
```

![kernel density estimation plot of penguins dataset generated with seaborn displot](/assets/3/kde.png)

Beautiful, right? One line of code gave us a publication-ready visualization with a clear legend, good colors, and proper styling. Recreating this with matplotlib would take dozens of lines.

The real superpower of figure-level functions, though, isn't just their aesthetics—it's their ability to create sophisticated faceted plots. Imagine automatically creating separate subplots for each category in your data, all with consistent styling and proper alignment. That's where figure-level functions shine, and we'll explore this capability in depth in Part 2 of this tutorial.

For now, we're going to focus on axes-level functions for two important reasons. First, they're easier to integrate into complex figures where you might want to mix Seaborn and matplotlib. Second, understanding axes-level functions gives you a solid foundation—once you master them, figure-level functions become intuitive.

Just remember: anything you can do with an axes-level function, you can also do with the corresponding figure-level function. They're two ways to achieve the same goal, each with different trade-offs.

## Your Essential Plot Types

Let's dive into the practical stuff. I'm going to walk you through the essential visualizations that every data scientist needs in their toolkit. We'll use real datasets to see how these plots work in practice, and I'll share insights about when each type of plot shines—and when you should avoid it.

For deeper dives into any of these, the [Seaborn official tutorial](https://seaborn.pydata.org/tutorial.html) is comprehensive and well-written.

---

## Bar Plots: Comparing Categories

Bar plots are everywhere, and there's a good reason for that. When you need to compare average values across categories, nothing beats a well-designed bar chart for immediate visual impact.

Think about presenting quarterly sales figures to your team. Numbers in a table make people's eyes glaze over. A bar plot tells the story instantly—which quarters performed well, which struggled, and by how much.

Let's work with an employee dataset to see this in practice:

```python
# Load data
df = pd.read_csv('data/employee.csv')
```

Seaborn offers four presentation styles: `paper`, `notebook`, `talk`, and `poster`. They're optimized for different contexts—from journal publications to conference presentations. The default is `notebook`, which works great for Jupyter notebooks and typical screens. You switch between them like this:

```python
sns.set_context("notebook", rc={"figure.figsize": (10, 6)})

sns.barplot(x=df['Department'], y=df['Age'])
plt.ylim(0, 45)
plt.title('Average Age by Department');
```

![Bar plot with seaborn of employees ages per department](/assets/3/bar.png)

The plot automatically shows the mean age for each department, with confidence intervals represented by the error bars. Those error bars are telling you something important: how certain we can be about these averages. Larger error bars mean more uncertainty.

Now, what if you want to add another dimension to your comparison? Maybe you're curious whether business travel frequency varies by department and affects age patterns. The `hue` parameter lets you split each bar into nested groups:

```python
sns.barplot(x=df['Department'], y=df['Age'],
            hue=df['BusinessTravel'],
            palette='magma_r')
plt.title('Average Age by Department and Travel Frequency');
```

![bar plot with nested grouping of variables](/assets/3/bar2.png)

Notice how we used a different color palette—`magma_r`. Seaborn includes six palette variations: `deep`, `muted`, `pastel`, `bright`, `dark`, and `colorblind`. That last one is important. If your work might be viewed by people with color vision deficiencies (and statistically, some of your audience probably will be), the `colorblind` palette ensures everyone can distinguish your categories.

Bar plots work best with a manageable number of categories. Beyond about ten, they become hard to read. Also, resist the temptation to use bar plots for continuous data—that's what scatter plots and line plots are for. Each visualization type has its purpose.

---

## Count Plots: Showing Distribution

While bar plots show aggregate statistics, count plots answer a simpler question: "How many of each category do I have?" It's like taking inventory.

This matters more than you might think. Before you build a classification model, you need to know whether your classes are balanced. Before you analyze survey responses, you need to understand your sample composition. Count plots give you this insight instantly.

```python
sns.countplot(df['EducationField'])
plt.xticks(rotation=45)
plt.title('Employee Distribution by Education Field');
```

![count plot with total number of employees and their degrees](/assets/3/count.png)

Now you can immediately see that life sciences and medical fields dominate this workforce, while human resources and technical degrees are underrepresented. This context matters when you're interpreting any analysis based on this data.

As with bar plots, you can add a second categorical variable with `hue`. Let's examine how employee attrition relates to education field:

```python
sns.countplot(x=df['EducationField'],
              hue=df['Attrition'],
              palette='colorblind')
plt.xticks(rotation=30)
plt.title('Attrition Rates by Education Field');
```

![count plot with hue](/assets/3/count2.png)

Interesting pattern emerging here—some fields show higher attrition rates than others. This single visualization could spark valuable conversations about retention strategies in different departments.

---

## Line Plots: Trends and Relationships

Here's where we need to pause for an important conversation. If you're coming from matplotlib or other libraries, Seaborn's line plots might surprise you. They don't just connect points—they do something more sophisticated.

By default, when Seaborn encounters multiple y-values for the same x-position, it aggregates them. It shows you the mean and wraps a confidence interval around it. This behavior is incredibly useful for time series and grouped data, but if you just want simple point-to-point lines, you might find it confusing.

Let's see what I mean:

```python
sns.lineplot(x=df['Department'], y=df['Age']);
```

![line plot with estimate of the central tendency and a confidence interval for the estimates](/assets/3/line.png)

That shaded region? It's showing you the 95% confidence interval around the mean age for each department. Seaborn is automatically computing statistics and visualizing uncertainty. Pretty neat, right?

This becomes even more powerful when you're comparing multiple groups:

```python
plt.style.use('ggplot')
sns.lineplot(x=df['Department'], y=df['Age'],
             hue=df['EducationField'])
plt.legend(loc='lower center', title='Education Field')
plt.title('Average Age by Department and Education Field');
```

![seaborn line plot with many lines and central tendency estimates](/assets/3/line3.png)

Now you're seeing trends across both department and education field simultaneously, with automatic handling of all the complexity underneath.

But here's the thing: computing confidence intervals is computationally expensive. If you're working with large datasets and those intervals aren't adding value to your analysis, turn them off:

```python
sns.lineplot(x=df['Department'], y=df['Age'],
             hue=df['EducationField'],
             ci=None)
plt.legend(loc='lower center', title='Education Field');
```

![seaborn lineplot with many lines without central tendency estimates](/assets/3/line4.png)

Much faster to render, and for large datasets (say, more than 10,000 points), the confidence intervals often become so narrow that they don't add much information anyway.

One more thing: if you want simple point-to-point line connections without any statistical aggregation, just use matplotlib's `plt.plot()` instead. There's no shame in that—use the right tool for the job.

---

## Scatter Plots: Exploring Relationships

If line plots show trends over sequences, scatter plots reveal relationships between two continuous variables. Each point is an observation, and patterns in the cloud of points tell you about correlations, clusters, and outliers.

Scatter plots are fundamental to exploratory data analysis. They help you discover relationships you didn't know existed and verify assumptions about relationships you suspected.

Let's work with the penguins dataset again. These are real measurements from three Antarctic penguin species, collected by researchers studying how body size relates to ecological niches:

```python
penguins = sns.load_dataset('penguins')

# Customize the appearance
sns.set_style('darkgrid')
sns.set_context("notebook", font_scale=1.3,
                rc={"figure.figsize": (10, 8)})

sns.scatterplot(data=penguins, x="flipper_length_mm",
                y="bill_length_mm", hue="species", s=60)

plt.xlabel("Flipper Length (mm)")
plt.ylabel("Bill Length (mm)");
```

![seaborn scatter plot of the penguins dataset](/assets/3/scatter1.png)

Look at how the species cluster—each occupies a distinct region of the plot. This isn't random; it reflects real biological differences in how these penguins have adapted to their environments. Adelie penguins (orange) are smaller overall, Gentoo (green) have long flippers relative to bill length, and Chinstrap (blue) sit in between.

Now, you can add even more dimensions to a scatter plot. Color (hue), size, and shape can all encode additional variables:

```python
markers = {'Male': 'o', 'Female': 'X'}

sns.set_context("notebook", font_scale=1.2,
                rc={"figure.figsize": (10, 8)})

sns.scatterplot(x="flipper_length_mm", y="bill_length_mm",
                hue="species", style='sex', size="body_mass_g",
                data=penguins, markers=markers,
                sizes=(20, 300), alpha=.5)
plt.legend(ncol=2, loc=4)
plt.xlabel("Flipper Length (mm)")
plt.ylabel("Bill Length (mm)");
```

![seaborn scatterplot with five dimensions](/assets/3/scatter2.png)

Technically impressive? Yes. Easy to interpret? Debatable. We're now encoding five dimensions: x-position, y-position, color, shape, and size. This can work for presentations where you guide people through the plot, but for written reports or exploratory analysis, simpler is usually better.

Here's a design principle worth remembering: more dimensions don't automatically mean better insights. If your plot becomes a puzzle to decode, you've gone too far. Sometimes the best solution is creating multiple simpler plots rather than one complex visualization.

There's one situation where you might prefer figure-level functions over axes-level: when your legend blocks important data. This happens when data fills the entire plot area and the legend is large. Here's the problem:

```python
plt.rcParams["figure.figsize"] = 8, 5
plt.style.use('fivethirtyeight')

sns.scatterplot(x=df['Age'], y=df['MonthlyRate'],
                hue=df['Department'],
                size=df['YearsAtCompany'],
                sizes=(20, 200), alpha=.3)
plt.xlim(29.5, 45.5)
plt.title('Age vs Monthly Rate');
```

![scatterplot with dots scattered over the entire axes instance](/assets/3/emp1.png)

See how the legend covers a chunk of data? Frustrating. The figure-level solution puts the legend outside:

```python
sns.relplot(x=df['Age'], y=df['MonthlyRate'],
            hue=df['Department'],
            size=df['YearsAtCompany'],
            sizes=(20, 200), alpha=.3, 
            kind="scatter",
            height=5, aspect=8/5)
plt.xlim(29.5, 45.5)
plt.title('Age vs Monthly Rate');
```

![scatterplot using the figure-level function sns.relplot()](/assets/3/em2.png)

Problem solved. This is one of those cases where the figure-level function's opinionated layout actually helps.

---

## Heat Maps: Seeing Patterns in Matrices

Some data naturally lives in a matrix—correlation coefficients, confusion matrices, missing data patterns. For this kind of data, heat maps are unbeatable. They encode matrix values as colors, letting you spot patterns at a glance that would be invisible in a table of numbers.

The classic use case is correlation matrices. Let's look at the Titanic dataset:

```python
titanic = sns.load_dataset('titanic')

sns.heatmap(titanic.corr(), annot=True, cmap='GnBu');
```

![heat map of the titanic dataframe correlation matrix](/assets/3/heat1.png)

The `annot=True` parameter displays the actual correlation values in each cell, while the color intensity provides immediate visual ranking. You can instantly see that fare and passenger class are strongly related (not surprising—first class tickets cost more), while age has weak correlations with most other variables.

But heat maps shine in another, often overlooked application: visualizing missing data. When data is missing, it's rarely random. The pattern of missingness often reveals something important about how your data was collected, and that insight can be valuable.

```python
sns.heatmap(titanic.isnull(), yticklabels=False, 
            cbar=False, cmap='YlOrRd');
```

![using heatmaps to show missing values](/assets/3/heat2.png)

The red streaks show missing values. Immediately you can see that the `deck` column is mostly empty, and `age` has scattered missingness throughout. This isn't just trivia—it affects how you should handle these variables in analysis. Maybe passengers in certain classes had deck information recorded while others didn't. Maybe age was left blank when passengers didn't provide it at booking.

Understanding missingness patterns can save you from making wrong assumptions later. If you want to go deeper into missing data analysis, check out the `missingno` library—it builds on matplotlib and Seaborn to provide specialized visualizations just for this purpose.

---

## Histograms: Understanding Distributions

If you want to understand a single variable's distribution, you start with a histogram. It's that fundamental. Histograms bin your data and show how many observations fall into each bin, revealing the shape, center, and spread of your distribution.

They answer questions like: Is this normally distributed? Are there outliers? Is the data skewed? These aren't academic questions—they directly impact which statistical methods you can validly apply.

Let's start simple:

```python
sns.histplot(data=penguins, x="flipper_length_mm");
```

![a simple histogram using seaborn](/assets/3/hist1.png)

You can see the distribution is roughly bell-shaped, maybe slightly left-skewed, with most flippers between 190 and 220 mm.

To understand the shape better, you can overlay a kernel density estimate—a smooth curve representing the underlying probability distribution:

```python
sns.histplot(data=penguins, x="flipper_length_mm",
             kde=True, color='red', bins=15);
```

![a histogram with kde](/assets/3/hist2.png)

The KDE curve shows you what the "true" distribution might look like if you had infinite data. It's particularly useful for spotting multiple peaks (multimodality) that might not be obvious from bars alone.

Now, what if you want to compare distributions across groups? The `hue` parameter creates overlaid histograms:

```python
sns.histplot(data=penguins, x="flipper_length_mm", 
             hue="species");
```

![multiple histograms on the same figure](/assets/3/hist3.png)

The overlapping bars can be hard to read though. An alternative is the step function approach:

```python
sns.histplot(data=penguins, x="flipper_length_mm", 
             hue="species", element="step");
```

![multiple histograms displayed as steps](/assets/3/hist4.png)

Much clearer! Seaborn automatically applies some transparency to help with visibility, but the step function makes comparison even easier.

Here's a more advanced technique. Sometimes you're comparing variables with dramatically different scales—imagine comparing the number of purchases (hundreds) with dollar amounts (thousands). Raw counts become incomparable. The solution is independent normalization:

```python
tips = sns.load_dataset('tips')

sns.histplot(tips, x="total_bill", hue="day", 
             multiple="stack",
             stat="density", common_norm=False,
             palette='pastel');
```

![multiple histograms stacked on the same figure](/assets/3/hist5.png)

Setting `common_norm=False` normalizes each distribution independently, so you're comparing shapes rather than absolute counts. This lets you see that Tuesday and Thursday have similar distribution shapes despite potentially having different numbers of observations.

Histograms have lots more options—different binning strategies, various normalization methods, cumulative distributions. The [official documentation](https://seaborn.pydata.org/generated/seaborn.histplot.html) is worth exploring when you need something specific.

---

## Box Plots: Compact Statistical Summaries

Sometimes you need to compare distributions across many categories, but creating separate histograms for each would be overwhelming. This is where box plots excel—they condense an entire distribution into five key numbers, displayed compactly enough that you can compare dozens of groups side by side.

Each box shows you the quartiles (25th, 50th, and 75th percentiles), the whiskers extend to the data's range, and individual points beyond the whiskers are flagged as potential outliers. It's an incredibly efficient use of space.

Let's work with the tips dataset—this captures restaurant tipping behavior:

```python
tips = sns.load_dataset('tips')
```

The data includes tip amounts, total bills, day of week, party size, and whether patrons were smokers. Here's what a grouped box plot looks like:

```python
sns.boxplot(x="day", y="total_bill",
            hue="smoker",
            data=tips,
            palette='coolwarm');
```

![Boxplots with hue](/assets/3/box.png)

You can immediately see patterns: bills tend to be higher on Saturday and Sunday, and within each day, smokers and non-smokers have similar distributions (the boxes overlap substantially).

Box plots were invented by statistician John Tukey back in the 1970s, designed to be drawn by hand when doing statistics with pencil and paper. Now that we have computers, we can create more sophisticated variations that show additional distribution details while keeping the compact format.

---

## Advanced Visualizations

These next plot types handle specialized situations—particularly large datasets or complex distributions that simpler plots struggle with.

### Letter-Value Plots: When Data Gets Big

Here's a problem you'll encounter with large datasets: traditional box plots show lots of "outliers" that aren't really anomalies—they're just the natural tails of large distributions. With 50,000 observations, even rare events appear hundreds of times. Flagging them all as outliers creates visual noise without adding insight.

Letter-value plots solve this by showing additional quantiles beyond the standard quartiles, giving you better representation of the tail behavior. Think of them as box plots that grow more detailed as your dataset grows larger.

Let's use the diamonds dataset, which has over 50,000 observations:

```python
diamonds = sns.load_dataset('diamonds')
plt.style.use('fivethirtyeight')

clarity_ranking = ["I1", "SI2", "SI1", "VS2", "VS1", "VVS2", "VVS1", "IF"]

sns.boxenplot(x="clarity", y="carat",
              color="b", order=clarity_ranking,
              scale="linear", data=diamonds,
              palette='RdBu');
```

![letter-value plots of a large dataset](/assets/3/boxen.png)

Compare this to a standard box plot of the same data:

```python
sns.boxplot(x="clarity", y="carat",
            color="b",
            order=clarity_ranking,
            data=diamonds,
            palette='RdBu')
```

![boxplot with seaborn for a large dataset](/assets/3/boxen2.png)

See the difference? The standard box plot is overwhelmed by thousands of "outlier" points that obscure the boxes themselves. The letter-value plot reveals the actual distribution structure that all those points represent.

Use letter-value plots when you have more than 10,000 observations and traditional box plots become cluttered. Below that size, regular box plots work fine.

---

## Violin Plots: Seeing the Full Shape

Box plots show you five numbers. Histograms show you the full distribution. Violin plots give you both—the complete distribution shape plus summary statistics, all in one compact visualization.

The width of the violin at any height shows you the density of observations at that value. It's like a mirror-image KDE plot, rotated vertically. The inner markings show the same summary statistics as a box plot.

![Suggestiveness of visualization types](/assets/3/xkcd.png)

*Even XKCD comics recognize the intuitive appeal of violin plots for showing distribution shape.*

Here's what makes violin plots clever: since they're symmetric, you can split them down the middle to compare two groups side-by-side. Let me show you:

```python
sns.set(style="whitegrid")
f, ax = plt.subplots(figsize=(8, 6))

sns.violinplot(x="day", y="total_bill",
               hue="smoker", data=tips,
               inner="box", split=True,
               palette="Set3_r", cut=2, 
               linewidth=3)

sns.despine(left=True)
ax.set_xlabel("Day", size=16, alpha=0.7)
ax.set_ylabel("Total Bill ($)", size=16, alpha=0.7)
ax.legend(loc=2, ncol=2, title='Smoker?')
f.suptitle('Total Bills by Day of the Week', fontsize=20)
```

![Violin plot of total bills from the tips dataset](/assets/3/vio1.png)

Reading this plot takes a moment to learn, but then it becomes second nature. The pink half-violins show the distribution of bills for smokers. The red half-violins show non-smokers. The inner box shows summary statistics for all bills combined on that day, regardless of smoking status.

You can also show separate summaries for each group:

```python
sns.violinplot(x="day", y="total_bill",
               hue="smoker", data=tips,
               inner="quart", split=True,
               palette="Set3_r", cut=2,
               linewidth=3)

sns.despine(left=True)
ax.set_xlabel("Day", size=16, alpha=0.7)
ax.set_ylabel("Total Bill ($)", size=16, alpha=0.7)
ax.legend(loc=2, ncol=2, title='Smoker?')
f.suptitle('Total Bills by Day of the Week', fontsize=20)
```

![Violin plot showing quartiles for each group](/assets/3/vio2.png)

Now the inner lines show quartiles separately for smokers and non-smokers, giving you even more granular information.

Violin plots work best with small to medium datasets where the distribution shape carries meaningful information. With very large datasets, the computational cost increases and the added detail may not justify the complexity.

---

## Regression Plots: Lines of Best Fit

Linear regression is one of the oldest statistical techniques, but it remains powerful for understanding relationships between variables. Regression plots visualize these relationships by fitting a line through your data and showing the uncertainty around that line.

A word of caution though: Seaborn will always draw a regression line, even when your data has no meaningful relationship. The line itself doesn't prove anything—you need to evaluate the relationship's strength statistically. Think of the plot as a visualization tool, not a statistical test.

Let's start simple:

```python
penguins = sns.load_dataset('penguins')
sns.set_theme(style="whitegrid", palette="colorblind")

sns.regplot(data=penguins, x='bill_length_mm', y='bill_depth_mm');
```

![penguins dataset: Linear regression bill length vs depth](/assets/3/reg1.png)

The plot suggests a negative relationship—as bill length increases, depth decreases. The shaded region shows the confidence interval for the regression line. But here's where things get interesting...

### When Aggregation Lies: Simpson's Paradox

The basic `regplot()` function has a limitation: no `hue` parameter. It can only show one regression line for all your data. For grouped data, this can be dangerously misleading. Watch what happens when we use `lmplot()`, which lets us separate by species:

```python
sns.lmplot(data=penguins, x='bill_length_mm',
           y='bill_depth_mm', hue='species',
           height=6, aspect=8/6,
           palette='cool');
```

![penguins dataset: Linear regression bill length vs depth with hue](/assets/3/reg0.png)

Wait, what? Now each species shows a **positive** relationship, completely contradicting the overall negative trend we saw before. This isn't an error—it's Simpson's Paradox in action.

Simpson's Paradox occurs when a trend in aggregated data reverses when you properly separate the data into meaningful groups. Here's what's happening: the three penguin species have different body plans. Gentoo penguins are generally larger with both longer and deeper bills. Adelie penguins are smaller on both dimensions. When you lump all species together, the between-species differences dominate the within-species pattern, creating a spurious negative correlation.

This is a crucial lesson for data analysis: always examine relationships within meaningful subgroups. Aggregating across distinct populations can produce completely misleading conclusions. The relationship you see in aggregated data might not exist at all—or worse, might be the opposite of the truth.

### Beyond Linear Relationships

Not everything is linear. For curved relationships, you can fit polynomial regressions:

```python
mpg = sns.load_dataset('mpg')

sns.regplot(data=mpg, x='horsepower', y='mpg', order=2);
```

![mpg dataset: second-order polynomial regression](/assets/3/reg2.png)

The `order=2` parameter fits a quadratic curve. Be careful though—higher-order polynomials can overfit your data, fitting noise rather than signal. Use them judiciously.

For binary outcomes, logistic regression is the right tool:

```python
# Generate binary outcome data
x = np.random.normal(size=150)
y = (x > 0).astype(np.float)
x = x.reshape(-1, 1)
x[x > 0] -= .8
x[x < 0] += .5

# Plot logistic regression
sns.regplot(x=x, y=y, logistic=True)
```

![Logistic regression example](/assets/3/mpg.png)

The S-shaped curve is characteristic of logistic regression, showing how probability changes with the predictor variable.

When should you use `regplot()` versus `lmplot()`? Use `regplot()` when you want a single regression as part of a larger matplotlib figure. Use `lmplot()` when you need separate regressions for different groups or want to create faceted regression plots.

---

## The Supporting Cast: Complementary Plots

These last few plot types rarely stand alone—they're best used as overlays on other visualizations, adding detail without overwhelming the viewer.

### Strip Plots: Showing Every Point

Sometimes summary statistics hide important details. You need to see the individual observations—how many there are, where they cluster, whether any stand out as unusual. Strip plots display every data point at categorical positions.

```python
plt.rcParams["figure.figsize"] = 7, 5
plt.style.use('fivethirtyeight')

params = dict(edgecolor='gray',
              palette=['#91bfdb', '#fc8d59'],
              linewidth=1,
              jitter=0.25)

sns.stripplot(data=titanic, x='pclass',
              hue='sex', y='age',
              **params);
```

![strip plot showing individual Titanic passenger ages](/assets/3/strip1.png)

The `jitter` parameter adds random horizontal displacement so overlapping points don't hide each other completely. Without jitter, they'd all stack vertically in lines, and you'd lose the sense of how many observations you have.

Strip plots shine when layered over violin or box plots:

```python
plt.rcParams["figure.figsize"] = 10, 6

# First plot the violins
sns.violinplot(x=titanic['pclass'], y=titanic['age'],
               palette='Accent', dodge=True,
               hue=titanic['survived'])

# Then overlay the strip plot
g = sns.stripplot(x=titanic['pclass'], y=titanic['age'],
                  edgecolor='gray',
                  palette=['#fc8d59', 'wheat'],
                  dodge=True,
                  hue=titanic['survived'],
                  jitter=.15);
```

![strip plot overlay on violin plot](/assets/3/strip2.png)

Now you see both the distribution shape and the actual data points. This combination works beautifully for datasets up to a few hundred points per group.

---

### Swarm Plots: Intelligent Point Placement

Strip plots add random jitter. Swarm plots do something smarter—they arrange points algorithmically to avoid overlap while revealing the distribution shape. The result looks like a swarm of bees, hence the name.

```python
sns.swarmplot(x=titanic['pclass'],
              y=titanic['age'],
              palette='icefire_r');
```

![swarm plot of Titanic passenger ages](/assets/3/swarm1.png)

The point arrangement itself shows you the distribution density. Where points spread wider, you have more observations. The shape emerges naturally from the algorithm trying to pack points efficiently.

The downside? Swarm plots are computationally expensive. With thousands of points, they become slow to render. They work best with small to medium datasets—say, under 2,000 points total.

Like strip plots, swarm plots pair beautifully with box plots:

```python
# First the swarm plot
sns.swarmplot(data=titanic, x='pclass',
              palette='PuBu', hue='survived',
              y='age')

# Then overlay the box plot with transparency
ax = sns.boxplot(x=titanic['pclass'],
                 y=titanic['age'],
                 palette="Accent")

# Add transparency to boxes
for patch in ax.artists:
    r, g, b, a = patch.get_facecolor()
    patch.set_facecolor((r, g, b, .5))
```

![swarm plot overlaid on box plot](/assets/3/swarm2.png)

Now you see individual points, distribution shape, and summary statistics all at once. It's a lot of information in one plot, but it works because each layer adds meaning without creating clutter.

---

### Rug Plots: Marginal Distributions

The humblest plot in our toolkit is the rug plot—just tiny tick marks along the axis showing where each data point sits. They're called rug plots because the marks resemble the fringe on a rug.

```python
fig, axs = plt.subplots(figsize=(8, 1.5))

sns.rugplot(ax=axs, a=tips['total_bill'],
            height=0.25, lw=0.5,
            color=sns.xkcd_rgb["pale red"]);
```

![rug plot showing distribution of bill totals](/assets/3/rug.png)

On their own, rug plots don't tell you much. But as marginal distributions alongside 2D visualizations like scatter plots or regression plots, they add context about the underlying data density. They answer the question "where is my data actually concentrated?" without interfering with the main visualization.

---

## Bringing It All Together

We've covered a lot of ground. You've learned why Seaborn exists, how it relates to matplotlib, and most importantly, how to create a wide range of visualizations with minimal code. Let's consolidate what you now know.

Seaborn's power comes from excellent defaults. The library makes aesthetic decisions that would take you hours to configure manually. It handles statistical computations automatically. It integrates seamlessly with pandas. These aren't just conveniences—they free you to focus on understanding your data rather than wrestling with plotting libraries.

You've learned that Seaborn functions come in two flavors—axes-level and figure-level—each with different trade-offs. Axes-level functions integrate into matplotlib figures and give you fine-grained control. Figure-level functions create complete, polished visualizations with less code but less flexibility. Neither is better—they're tools for different jobs.

Most importantly, you now have a toolkit of essential visualizations:

Bar plots and count plots for categorical comparisons. Line plots for trends with uncertainty. Scatter plots for exploring relationships. Heat maps for matrix data and correlations. Histograms for understanding distributions. Box plots for compact statistical summaries. And specialized plots like violins, letter-value plots, and regression plots for specific scenarios.

Each visualization type has its place. The key is choosing the right one for your data structure and communication goal. A histogram makes no sense for categorical data. A bar plot obscures patterns in continuous relationships. Match the tool to the task.

## Your Quick Reference

When you're working on a real analysis and need to remember which function to use, here's your cheat sheet:

**For categorical comparisons:** Start with bar plots (`barplot`) for means or count plots (`countplot`) for frequencies. Add `hue` for nested grouping.

**For distributions:** Histograms (`histplot`) are your go-to. Add `kde=True` to overlay density estimates. For comparing multiple distributions, try `element="step"` for clarity.

**For relationships between continuous variables:** Scatter plots (`scatterplot`) reveal correlations and clusters. Add regression lines with `regplot` or `lmplot`, but always verify statistical significance separately.

**For compact statistical summaries:** Box plots (`boxplot`) work well for moderate sample sizes. Switch to letter-value plots (`boxenplot`) when you have 10,000+ observations. Violin plots (`violinplot`) show full distribution shape when that matters.

**For matrix data:** Heat maps (`heatmap`) excel at correlation matrices and missing data patterns. Use `annot=True` to show values in cells.

**For adding detail:** Strip plots (`stripplot`) and swarm plots (`swarmplot`) show individual points. Rug plots (`rugplot`) add marginal distributions. Layer these over summary plots for richer visualizations.

Remember Simpson's Paradox: patterns in aggregated data can reverse when you properly separate groups. Always explore relationships within meaningful subgroups, not just across the entire dataset.

## What's Next?

This tutorial covered axes-level functions primarily because they're easier to integrate into complex figures and they build solid conceptual foundations. But figure-level functions unlock even more power, especially for faceted visualizations.

In Part 2, we'll explore FacetGrid—Seaborn's system for automatically creating multi-panel plots across subsets of your data. Imagine creating separate plots for every category in a variable with a single line of code, all styled consistently. We'll also cover PairGrid and JointGrid for specialized multivariate layouts, advanced customization techniques, and performance optimization for large datasets.

For now, you have everything you need to create publication-quality visualizations efficiently. The best way to solidify this knowledge is to use it—pick a dataset you're curious about and start exploring. You'll be surprised how quickly these patterns become second nature.

## Resources for Going Deeper

The [Seaborn official tutorial](https://seaborn.pydata.org/tutorial.html) is comprehensive and well-maintained. The [example gallery](https://seaborn.pydata.org/examples/index.html) shows what's possible and provides code for each visualization. When you need details about specific parameters, the [API reference](https://seaborn.pydata.org/api.html) is authoritative.

All the code from this tutorial, along with the datasets used, is available in [this GitHub repository](https://github.com/skacem/TIL/blob/main/seaborn_intro.ipynb). Feel free to download and experiment.

Now go create something beautiful.

---

## References

[1] VanderPlas, Jake. 2016. *Python Data Science Handbook*. O'Reilly Media, Inc.

[2] [Matplotlib - Axes Class](https://www.tutorialspoint.com/matplotlib/matplotlib_axes_class.htm)

[3] Desai, Meet. "Matplotlib + Seaborn + Pandas." Medium, Towards Data Science, 30 Oct. 2019

[4] Waskom, M. L., (2021). seaborn: statistical data visualization. *Journal of Open Source Software*, 6(60), 3021, https://doi.org/10.21105/joss.03021

[5] Gureckis, Todd. 2020. [Lab in Cognition and Perception](http://gureckislab.org/courses/spring20/labincp/intro)

[6] Hofmann, Heike, Hadley Wickham & Karen Kafadar (2017) Letter-Value Plots: Boxplots for Large Data, *Journal of Computational and Graphical Statistics*, 26:3, 469-477, DOI: 10.1080/10618600.2017.1305277
